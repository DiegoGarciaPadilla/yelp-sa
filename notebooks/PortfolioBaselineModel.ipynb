{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1627e3",
   "metadata": {},
   "source": [
    "# Baseline Model (Logistic Regression)\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Diego Antonio Garc√≠a Padilla\n",
    "\n",
    "**Date:** Nov 3, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1788db",
   "metadata": {},
   "source": [
    "## Enviroment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfcd4855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENVIRONMENT CHECK ===\n",
      "Python: 3.10.12\n",
      "JAVA_HOME: /usr/lib/jvm/java-8-openjdk-arm64/jre\n",
      "SPARK_HOME: /opt/spark\n",
      "Driver Memory: 12g\n",
      "Executor Memory: 8g\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#@title Setup & Environment Verification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=== ENVIRONMENT CHECK ===\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"JAVA_HOME: {os.environ.get('JAVA_HOME')}\")\n",
    "print(f\"SPARK_HOME: {os.environ.get('SPARK_HOME')}\")\n",
    "print(f\"Driver Memory: {os.environ.get('SPARK_DRIVER_MEMORY')}\")\n",
    "print(f\"Executor Memory: {os.environ.get('SPARK_EXECUTOR_MEMORY')}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8a5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import Libraries\n",
    "\n",
    "# PySpark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, HashingTF, IDF, StringIndexer\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# SciKit Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Financial data\n",
    "import yfinance as yf\n",
    "\n",
    "# Hugging Face\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5058e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-FLIGHT CHECK ===\n",
      "Java: ‚úÖ Available\n",
      "==================================================\n",
      "üßπ Cleaned up existing Spark session\n",
      "==================================================\n",
      "‚úÖ Spark session configured with:\n",
      "   - Driver Memory: 12GB\n",
      "   - Executor Memory: 8GB\n",
      "   - Max Result Size: 4GB\n",
      "   - Parallelism: 16 cores\n",
      "   - Shuffle Partitions: 200\n"
     ]
    }
   ],
   "source": [
    "#@title Start Spark session\n",
    "\n",
    "print(\"=== PRE-FLIGHT CHECK ===\")\n",
    "\n",
    "# Verify Java is available\n",
    "try:\n",
    "    java_version = subprocess.check_output(['java', '-version'], stderr=subprocess.STDOUT)\n",
    "    print(\"Java: ‚úÖ Available\")\n",
    "except Exception as e:\n",
    "    print(f\"Java: ‚ùå Not available - {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# üî• STOP any existing Spark sessions first\n",
    "try:\n",
    "    SparkContext.getOrCreate().stop()\n",
    "    print(\"üßπ Cleaned up existing Spark session\")\n",
    "except:\n",
    "    print(\"üÜï No existing session to clean\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create fresh Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Yelp_Sentiment_Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.default.parallelism\", \"16\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"512m\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"‚úÖ Spark session configured with:\")\n",
    "print(f\"   - Driver Memory: 12GB\")\n",
    "print(f\"   - Executor Memory: 8GB\")\n",
    "print(f\"   - Max Result Size: 4GB\")\n",
    "print(f\"   - Parallelism: 16 cores\")\n",
    "print(f\"   - Shuffle Partitions: 200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975695ac",
   "metadata": {},
   "source": [
    "## Logistic Regression with MLlib (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e034c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Schema of Yelp Reviews:\n",
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- text_length: integer (nullable = true)\n",
      " |-- word_count: integer (nullable = true)\n",
      " |-- text_clean: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tokens_filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "\n",
      "üìã Sample:\n",
      "+--------------------------------------------------------------------------------+---------+-----------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|                                                                            text|sentiment|text_length|word_count|                                                                      text_clean|                                                                          tokens|                                                                 tokens_filtered|\n",
      "+--------------------------------------------------------------------------------+---------+-----------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|The food is excellent. The customer service and quantity over time has contin...| negative|        675|       136|the food is excellent the customer service and quantity over time has continu...|[the, food, is, excellent, the, customer, service, and, quantity, over, time,...|[food, excellent, customer, service, quantity, time, continued, go, ive, goin...|\n",
      "|I have only ever gotten take-out at the Bridgeport Rib House, so I can only c...| negative|        331|        62|i have only ever gotten takeout at the bridgeport rib house so i can only com...|[i, have, only, ever, gotten, takeout, at, the, bridgeport, rib, house, so, i...|[ever, gotten, takeout, bridgeport, rib, house, comment, , numerous, visits, ...|\n",
      "|Cleanliness is an issue here.  It's a great spot for a quick toenail trim but...| negative|        238|        51|cleanliness is an issue here  its a great spot for a quick toenail trim but i...|[cleanliness, is, an, issue, here, , its, a, great, spot, for, a, quick, toen...|[cleanliness, issue, , great, spot, quick, toenail, trim, smells, like, dog, ...|\n",
      "|I really wanted to love this place since quite a few of my friends just visit...| negative|       2986|       560|i really wanted to love this place since quite a few of my friends just visit...|[i, really, wanted, to, love, this, place, since, quite, a, few, of, my, frie...|[really, wanted, love, place, since, quite, friends, visited, past, week, las...|\n",
      "|We went here for breakfast and will never return! This restaurant is filthy! ...| negative|        462|        82|we went here for breakfast and will never return this restaurant is filthy fl...|[we, went, here, for, breakfast, and, will, never, return, this, restaurant, ...|[went, breakfast, never, return, restaurant, filthy, floors, walls, windows, ...|\n",
      "+--------------------------------------------------------------------------------+---------+-----------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Load dataset\n",
    "\n",
    "# Parquet path\n",
    "parquet_path = \"../data/clean/yelp_reviews_tokenized.parquet\"\n",
    "\n",
    "yelp_df = spark.read.parquet(parquet_path)\n",
    "\n",
    "# Show schema to understand structure\n",
    "print(\"üìã Schema of Yelp Reviews:\")\n",
    "yelp_df.printSchema()\n",
    "\n",
    "# Sample\n",
    "print(\"\\nüìã Sample:\")\n",
    "yelp_df.show(5, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "750949fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Train:  291152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation:  62355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==============================================>          (13 + 3) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Test:  61924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#@ Split data into train, valdation and test\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "train_df, temp_df = yelp_df.randomSplit([0.7, 0.3], seed=42)\n",
    "val_df, test_df = temp_df.randomSplit([0.5, 0.5], seed=42)\n",
    "\n",
    "print(\"üìä Train: \", train_df.count())\n",
    "print(\"üìä Validation: \", val_df.count())\n",
    "print(\"üìä Test: \", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "975695ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéØ BASELINE MODEL: Logistic Regression with TF-IDF\n",
      "================================================================================\n",
      "\n",
      "‚è≥ Training baseline model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Making predictions on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìà BASELINE RESULTS\n",
      "================================================================================\n",
      "Validation Accuracy: 0.7533\n",
      "Validation F1-Score: 0.7520\n",
      "Test Accuracy:       0.7542\n",
      "Test F1-Score:       0.7532\n",
      "================================================================================\n",
      "\n",
      "üîç Sample predictions (validation):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+---------+----------+\n",
      "|                                                                            text|sentiment|prediction|\n",
      "+--------------------------------------------------------------------------------+---------+----------+\n",
      "|\" after a previous that was awful I decided to give the bridal garden one mor...| negative|       0.0|\n",
      "|\" you are killing me Larry\". The ice cream is amazing. The staff was amazing,...| negative|       2.0|\n",
      "|\"Drishti is a point of gaze or focus. Drishti mainly means not looking at an ...| negative|       0.0|\n",
      "|\"Flavor of Indian\" huh? What flavor would that be? This place is as blah as t...| negative|       0.0|\n",
      "|\"Loss prevention\" undercover in that store must have followed me through the ...| negative|       0.0|\n",
      "+--------------------------------------------------------------------------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üíæ Baseline model saved to: ../models/baseline_lr_tfidf\n"
     ]
    }
   ],
   "source": [
    "#@title Logistic Regression with TF-IDF (MLlib)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ BASELINE MODEL: Logistic Regression with TF-IDF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Convert sentiment labels to numerical indices\n",
    "# 0 -> Negative\n",
    "# 1 -> Neutral\n",
    "# 2 -> Positive\n",
    "label_indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n",
    "\n",
    "# Step 2: TF-IDF feature extraction\n",
    "# HashingTF: converts tokens to term frequency vectors\n",
    "hashingTF = HashingTF(inputCol=\"tokens_filtered\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "\n",
    "# IDF: applies inverse document frequency weighting\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Step 3: Logistic Regression classifier\n",
    "lr = LogisticRegression(\n",
    "    maxIter=20,\n",
    "    regParam=0.01,  # L2 regularization\n",
    "    elasticNetParam=0.0  # Pure L2 (ridge)\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "baseline_pipeline = Pipeline(stages=[label_indexer, hashingTF, idf, lr])\n",
    "\n",
    "# Train model\n",
    "print(\"\\n‚è≥ Training baseline model...\")\n",
    "baseline_model = baseline_pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nüìä Making predictions on validation set...\")\n",
    "val_predictions = baseline_model.transform(val_df)\n",
    "test_predictions = baseline_model.transform(test_df)\n",
    "\n",
    "# Evaluate\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "val_accuracy = evaluator_accuracy.evaluate(val_predictions)\n",
    "val_f1 = evaluator_f1.evaluate(val_predictions)\n",
    "\n",
    "test_accuracy = evaluator_accuracy.evaluate(test_predictions)\n",
    "test_f1 = evaluator_f1.evaluate(test_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà BASELINE RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1-Score: {val_f1:.4f}\")\n",
    "print(f\"Test Accuracy:       {test_accuracy:.4f}\")\n",
    "print(f\"Test F1-Score:       {test_f1:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show confusion matrix (validation)\n",
    "print(\"\\nüîç Sample predictions (validation):\")\n",
    "val_predictions.select('text', 'sentiment', 'prediction').show(5, truncate=80)\n",
    "\n",
    "# Save baseline model\n",
    "baseline_model_path = \"../models/baseline_lr_tfidf\"\n",
    "baseline_model.write().overwrite().save(baseline_model_path)\n",
    "print(f\"\\nüíæ Baseline model saved to: {baseline_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d0d377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä PREPARING DATA FOR TABLEAU\n",
      "================================================================================\n",
      "\n",
      "üìã Sample data for Tableau:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+--------------+----------+---------------+-----------+----------+-------------------+----------+\n",
      "|                                                                            text|true_sentiment|true_label|predicted_label|text_length|word_count|predicted_sentiment|is_correct|\n",
      "+--------------------------------------------------------------------------------+--------------+----------+---------------+-----------+----------+-------------------+----------+\n",
      "|!! FRAUD ALERT / SCAM / BUYER BEWARE !!\\n\\nUses cross state Craigslist posts ...|      negative|       0.0|            0.0|       2017|       322|           negative|         1|\n",
      "|\" Venture N is an absolute horrible place to go if you want to have good cust...|      negative|       0.0|            0.0|        345|        67|           negative|         1|\n",
      "|\"Bouncer\" at the door was a tool. Wouldn't let us in because we weren't on so...|      negative|       0.0|            0.0|        335|        58|           negative|         1|\n",
      "|\"Burritos as big as your head\" -- that sounds like a great idea! It's not suc...|      negative|       0.0|            1.0|        330|        63|            neutral|         0|\n",
      "|\"Carside to Go\" is apparently a very confusing concept to this Applebees staf...|      negative|       0.0|            1.0|        542|        97|            neutral|         0|\n",
      "+--------------------------------------------------------------------------------+--------------+----------+---------------+-----------+----------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üîç VERIFICATION:\n",
      "Total predictions: 61,924\n",
      "Correct predictions: 46,705 (75.42%)\n",
      "Incorrect predictions: 15,219 (24.58%)\n",
      "Test Accuracy from model: 0.7542 (75.42%)\n",
      "Match? True\n",
      "\n",
      "üéØ Creating balanced sample (equal representation of all sentiments)...\n",
      "\n",
      "üìä Sample distribution:\n",
      "+--------------+-----+\n",
      "|true_sentiment|count|\n",
      "+--------------+-----+\n",
      "|      negative| 3333|\n",
      "|       neutral| 3333|\n",
      "|      positive| 3333|\n",
      "+--------------+-----+\n",
      "\n",
      "\n",
      "üßπ Cleaning text for CSV export...\n",
      "\n",
      "‚úÖ Balanced sample created with all 3 sentiments!\n",
      "+--------------------------------------------------------------------------------+--------------+----------+-------------------+---------------+-----------+----------+----------+\n",
      "|                                                                  text_truncated|true_sentiment|true_label|predicted_sentiment|predicted_label|text_length|word_count|is_correct|\n",
      "+--------------------------------------------------------------------------------+--------------+----------+-------------------+---------------+-----------+----------+----------+\n",
      "|!! FRAUD ALERT / SCAM / BUYER BEWARE !! Uses cross state Craigslist posts for...|      negative|       0.0|           negative|            0.0|       2017|       322|         1|\n",
      "| Venture N is an absolute horrible place to go if you want to have good custo...|      negative|       0.0|           negative|            0.0|        345|        67|         1|\n",
      "|Bouncer at the door was a tool. Wouldn't let us in because we weren't on some...|      negative|       0.0|           negative|            0.0|        335|        58|         1|\n",
      "|Burritos as big as your head -- that sounds like a great idea! It's not such ...|      negative|       0.0|            neutral|            1.0|        330|        63|         0|\n",
      "|Carside to Go is apparently a very confusing concept to this Applebees staff....|      negative|       0.0|            neutral|            1.0|        542|        97|         0|\n",
      "+--------------------------------------------------------------------------------+--------------+----------+-------------------+---------------+-----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üìä Creating confusion matrix data...\n",
      "\n",
      "üî¢ Confusion Matrix:\n",
      "+--------------+-------------------+-----+\n",
      "|true_sentiment|predicted_sentiment|count|\n",
      "+--------------+-------------------+-----+\n",
      "|      negative|           negative|16254|\n",
      "|      negative|            neutral| 3564|\n",
      "|      negative|           positive|  762|\n",
      "|       neutral|           negative| 3707|\n",
      "|       neutral|            neutral|13324|\n",
      "|       neutral|           positive| 3657|\n",
      "|      positive|           negative|  593|\n",
      "|      positive|            neutral| 2936|\n",
      "|      positive|           positive|17127|\n",
      "+--------------+-------------------+-----+\n",
      "\n",
      "\n",
      "üìà Creating per-class metrics...\n",
      "\n",
      "üìä Per-class metrics:\n",
      "+--------+---------------+---------------+---------+------+---------+--------------+--------------+\n",
      "|f1_score|false_negatives|false_positives|precision|recall|sentiment|true_negatives|true_positives|\n",
      "+--------+---------------+---------------+---------+------+---------+--------------+--------------+\n",
      "|  0.7903|           4326|           4300|   0.7908|0.7898| negative|         37044|         16254|\n",
      "|  0.6578|           7364|           6500|   0.6721| 0.644|  neutral|         34736|         13324|\n",
      "|  0.8117|           3529|           4419|   0.7949|0.8292| positive|         36849|         17127|\n",
      "+--------+---------------+---------------+---------+------+---------+--------------+--------------+\n",
      "\n",
      "\n",
      "üìè Creating text length analysis...\n",
      "\n",
      "üìä Text length by sentiment and correctness:\n",
      "+--------------+----------+-----------------+------------------+-----+\n",
      "|true_sentiment|is_correct|  avg_text_length|    avg_word_count|count|\n",
      "+--------------+----------+-----------------+------------------+-----+\n",
      "|      negative|         0|675.4239482200647|126.82709200184928| 4326|\n",
      "|      negative|         1|730.4203273040482|138.44167589516428|16254|\n",
      "|       neutral|         1|698.3151456019214| 130.5689732812969|13324|\n",
      "|       neutral|         0|613.2395437262358|114.88796849538295| 7364|\n",
      "|      positive|         1|468.0737432124715| 86.27395340690138|17127|\n",
      "|      positive|         0|647.3884953244545|120.92320770756588| 3529|\n",
      "+--------------+----------+-----------------+------------------+-----+\n",
      "\n",
      "\n",
      "üíæ Exporting to CSV for Tableau using Spark...\n",
      "\n",
      "‚è≥ Saving balanced predictions sample...\n",
      "\n",
      "‚è≥ Saving confusion matrix...\n",
      "\n",
      "‚è≥ Saving per-class metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Saving text length analysis...\n",
      "\n",
      "‚è≥ Saving model summary...\n",
      "\n",
      "üìä Model Summary:\n",
      "+--------+------------------+-------------------+--------+--------------------+---------------------+----------------------+-----------------+\n",
      "|accuracy|correct_percentage|correct_predictions|f1_score|incorrect_percentage|incorrect_predictions|model_name            |total_predictions|\n",
      "+--------+------------------+-------------------+--------+--------------------+---------------------+----------------------+-----------------+\n",
      "|0.7542  |75.42             |46705              |0.7532  |24.58               |15219                |Baseline (LR + TF-IDF)|61924            |\n",
      "+--------+------------------+-------------------+--------+--------------------+---------------------+----------------------+-----------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ALL DATA EXPORTED FOR TABLEAU!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Files saved to: ../data/tableau/\n",
      "\n",
      "üéØ Predictions sample now contains BALANCED data:\n",
      "   - ~3,333 negative reviews\n",
      "   - ~3,333 neutral reviews\n",
      "   - ~3,333 positive reviews\n"
     ]
    }
   ],
   "source": [
    "#@title Export predictions for Tableau \n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä PREPARING DATA FOR TABLEAU\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Get predictions with all relevant info\n",
    "tableau_predictions = test_predictions.select(\n",
    "    F.col('text'),\n",
    "    F.col('sentiment').alias('true_sentiment'),\n",
    "    F.col('label').alias('true_label'),\n",
    "    F.col('prediction').alias('predicted_label'),\n",
    "    F.col('text_length'),\n",
    "    F.col('word_count')\n",
    ").withColumn('predicted_sentiment',\n",
    "    F.when(F.col('predicted_label') == 0.0, 'negative')\n",
    "    .when(F.col('predicted_label') == 1.0, 'neutral')\n",
    "    .when(F.col('predicted_label') == 2.0, 'positive')\n",
    "    .otherwise('unknown')\n",
    ").withColumn('is_correct',\n",
    "    F.when(F.col('true_label') == F.col('predicted_label'), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Cache it for reuse\n",
    "tableau_predictions.cache()\n",
    "\n",
    "print(\"\\nüìã Sample data for Tableau:\")\n",
    "tableau_predictions.show(5, truncate=80)\n",
    "\n",
    "# VERIFY counts first\n",
    "total_count = tableau_predictions.count()\n",
    "correct_count = tableau_predictions.filter(F.col('is_correct') == 1).count()\n",
    "incorrect_count = tableau_predictions.filter(F.col('is_correct') == 0).count()\n",
    "\n",
    "print(f\"\\nüîç VERIFICATION:\")\n",
    "print(f\"Total predictions: {total_count:,}\")\n",
    "print(f\"Correct predictions: {correct_count:,} ({correct_count/total_count*100:.2f}%)\")\n",
    "print(f\"Incorrect predictions: {incorrect_count:,} ({incorrect_count/total_count*100:.2f}%)\")\n",
    "print(f\"Test Accuracy from model: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Match? {abs((correct_count/total_count) - test_accuracy) < 0.01}\")\n",
    "\n",
    "# 2. Create BALANCED & CLEAN predictions sample for Tableau\n",
    "print(\"\\nüéØ Creating balanced sample (equal representation of all sentiments)...\")\n",
    "\n",
    "# Take equal samples from each sentiment class\n",
    "sample_size_per_class = 3333  # 3333 * 3 = ~10,000 total\n",
    "\n",
    "negative_sample = tableau_predictions.filter(F.col('true_sentiment') == 'negative').limit(sample_size_per_class)\n",
    "neutral_sample = tableau_predictions.filter(F.col('true_sentiment') == 'neutral').limit(sample_size_per_class)\n",
    "positive_sample = tableau_predictions.filter(F.col('true_sentiment') == 'positive').limit(sample_size_per_class)\n",
    "\n",
    "# Union all samples\n",
    "balanced_sample = negative_sample.union(neutral_sample).union(positive_sample)\n",
    "\n",
    "print(f\"\\nüìä Sample distribution:\")\n",
    "balanced_sample.groupBy('true_sentiment').count().orderBy('true_sentiment').show()\n",
    "\n",
    "# Clean text: remove newlines, tabs, and extra spaces\n",
    "print(\"\\nüßπ Cleaning text for CSV export...\")\n",
    "\n",
    "predictions_clean = balanced_sample.withColumn('text_clean',\n",
    "    F.regexp_replace(\n",
    "        F.regexp_replace(\n",
    "            F.regexp_replace(F.col('text'), r'[\\n\\r\\t]+', ' '),  # Replace newlines/tabs with space\n",
    "        r'\\s+', ' '),  # Replace multiple spaces with single space\n",
    "    r'[\\\"]+', '')  # Remove double quotes\n",
    ").withColumn('text_truncated',\n",
    "    F.substring(F.col('text_clean'), 1, 500)  # Limit to 500 chars for Tableau\n",
    ").select(\n",
    "    'text_truncated',\n",
    "    'true_sentiment',\n",
    "    'true_label',\n",
    "    'predicted_sentiment',\n",
    "    'predicted_label',\n",
    "    'text_length',\n",
    "    'word_count',\n",
    "    'is_correct'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Balanced sample created with all 3 sentiments!\")\n",
    "predictions_clean.show(5, truncate=80)\n",
    "\n",
    "# 3. Create confusion matrix data\n",
    "print(\"\\nüìä Creating confusion matrix data...\")\n",
    "confusion_matrix = tableau_predictions.groupBy('true_sentiment', 'predicted_sentiment').count()\n",
    "\n",
    "print(\"\\nüî¢ Confusion Matrix:\")\n",
    "confusion_matrix.orderBy('true_sentiment', 'predicted_sentiment').show()\n",
    "\n",
    "# 4. Calculate metrics per class\n",
    "print(\"\\nüìà Creating per-class metrics...\")\n",
    "\n",
    "metrics_list = []\n",
    "for class_idx, class_name in enumerate(['negative', 'neutral', 'positive']):\n",
    "    tp = tableau_predictions.filter(\n",
    "        (F.col('true_label') == class_idx) & (F.col('predicted_label') == class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    fp = tableau_predictions.filter(\n",
    "        (F.col('true_label') != class_idx) & (F.col('predicted_label') == class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    fn = tableau_predictions.filter(\n",
    "        (F.col('true_label') == class_idx) & (F.col('predicted_label') != class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    tn = tableau_predictions.filter(\n",
    "        (F.col('true_label') != class_idx) & (F.col('predicted_label') != class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    metrics_list.append({\n",
    "        'sentiment': class_name,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn,\n",
    "        'true_negatives': tn,\n",
    "        'precision': round(precision, 4),\n",
    "        'recall': round(recall, 4),\n",
    "        'f1_score': round(f1, 4)\n",
    "    })\n",
    "\n",
    "metrics_df = spark.createDataFrame(metrics_list)\n",
    "print(\"\\nüìä Per-class metrics:\")\n",
    "metrics_df.show()\n",
    "\n",
    "# 5. Text length analysis\n",
    "print(\"\\nüìè Creating text length analysis...\")\n",
    "length_analysis = tableau_predictions.groupBy('true_sentiment', 'is_correct').agg(\n",
    "    F.avg('text_length').alias('avg_text_length'),\n",
    "    F.avg('word_count').alias('avg_word_count'),\n",
    "    F.count('*').alias('count')\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Text length by sentiment and correctness:\")\n",
    "length_analysis.show()\n",
    "\n",
    "# 6. Export everything using Spark with proper CSV options\n",
    "print(\"\\nüíæ Exporting to CSV for Tableau using Spark...\")\n",
    "\n",
    "output_dir = \"../data/tableau\"\n",
    "\n",
    "# CSV options for clean export\n",
    "csv_options = {\n",
    "    'header': 'true',\n",
    "    'quote': '\"',\n",
    "    'escape': '\"',\n",
    "    'quoteAll': 'true'  # Quote all fields to avoid issues\n",
    "}\n",
    "\n",
    "print(\"\\n‚è≥ Saving balanced predictions sample...\")\n",
    "predictions_clean.coalesce(1).write.mode('overwrite').options(**csv_options).csv(f\"{output_dir}/predictions_sample\")\n",
    "\n",
    "print(\"\\n‚è≥ Saving confusion matrix...\")\n",
    "confusion_matrix.coalesce(1).write.mode('overwrite').options(**csv_options).csv(f\"{output_dir}/confusion_matrix\")\n",
    "\n",
    "print(\"\\n‚è≥ Saving per-class metrics...\")\n",
    "metrics_df.coalesce(1).write.mode('overwrite').options(**csv_options).csv(f\"{output_dir}/metrics_per_class\")\n",
    "\n",
    "print(\"\\n‚è≥ Saving text length analysis...\")\n",
    "length_analysis.coalesce(1).write.mode('overwrite').options(**csv_options).csv(f\"{output_dir}/text_length_analysis\")\n",
    "\n",
    "# 7. Create and save summary - WITH CORRECT COUNTS\n",
    "print(\"\\n‚è≥ Saving model summary...\")\n",
    "overall_summary = spark.createDataFrame([{\n",
    "    'model_name': 'Baseline (LR + TF-IDF)',\n",
    "    'accuracy': round(test_accuracy, 4),\n",
    "    'f1_score': round(test_f1, 4),\n",
    "    'total_predictions': total_count,\n",
    "    'correct_predictions': correct_count,\n",
    "    'incorrect_predictions': incorrect_count,\n",
    "    'correct_percentage': round((correct_count/total_count)*100, 2),\n",
    "    'incorrect_percentage': round((incorrect_count/total_count)*100, 2)\n",
    "}])\n",
    "\n",
    "print(\"\\nüìä Model Summary:\")\n",
    "overall_summary.show(truncate=False)\n",
    "overall_summary.coalesce(1).write.mode('overwrite').options(**csv_options).csv(f\"{output_dir}/model_summary\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ ALL DATA EXPORTED FOR TABLEAU!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìÅ Files saved to: {output_dir}/\")\n",
    "print(\"\\nüéØ Predictions sample now contains BALANCED data:\")\n",
    "print(\"   - ~3,333 negative reviews\")\n",
    "print(\"   - ~3,333 neutral reviews\")\n",
    "print(\"   - ~3,333 positive reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "656c0328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ predictions_sample.csv created\n",
      "‚úÖ confusion_matrix.csv created\n",
      "‚úÖ metrics_per_class.csv created\n",
      "‚úÖ text_length_analysis.csv created\n",
      "‚úÖ model_summary.csv created\n",
      "\n",
      "üéâ Clean CSVs ready for Tableau!\n"
     ]
    }
   ],
   "source": [
    "#@title Consolidate CSVs\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Move CSV files out of Spark folders\n",
    "output_dir = \"../data/tableau\"\n",
    "folders = ['predictions_sample', 'confusion_matrix', 'metrics_per_class', \n",
    "           'text_length_analysis', 'model_summary']\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = f\"{output_dir}/{folder}\"\n",
    "    csv_files = glob.glob(f\"{folder_path}/part-*.csv\")\n",
    "    \n",
    "    if csv_files:\n",
    "        csv_file = csv_files[0]\n",
    "        new_path = f\"{output_dir}/{folder}.csv\"\n",
    "        shutil.copy(csv_file, new_path)\n",
    "        print(f\"‚úÖ {folder}.csv created\")\n",
    "\n",
    "print(\"\\nüéâ Clean CSVs ready for Tableau!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
