{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1627e3",
   "metadata": {},
   "source": [
    "# Baseline Model (Logistic Regression)\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Diego Antonio Garc√≠a Padilla\n",
    "\n",
    "**Date:** Nov 3, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1788db",
   "metadata": {},
   "source": [
    "## Enviroment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfcd4855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENVIRONMENT CHECK ===\n",
      "Python: 3.10.12\n",
      "JAVA_HOME: /usr/lib/jvm/java-8-openjdk-arm64/jre\n",
      "SPARK_HOME: /opt/spark\n",
      "Driver Memory: 12g\n",
      "Executor Memory: 8g\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#@title Setup & Environment Verification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=== ENVIRONMENT CHECK ===\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"JAVA_HOME: {os.environ.get('JAVA_HOME')}\")\n",
    "print(f\"SPARK_HOME: {os.environ.get('SPARK_HOME')}\")\n",
    "print(f\"Driver Memory: {os.environ.get('SPARK_DRIVER_MEMORY')}\")\n",
    "print(f\"Executor Memory: {os.environ.get('SPARK_EXECUTOR_MEMORY')}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8a5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import Libraries\n",
    "\n",
    "# PySpark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, HashingTF, IDF, StringIndexer\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# SciKit Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Financial data\n",
    "import yfinance as yf\n",
    "\n",
    "# Hugging Face\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5058e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-FLIGHT CHECK ===\n",
      "Java: ‚úÖ Available\n",
      "==================================================\n",
      "üßπ Cleaned up existing Spark session\n",
      "==================================================\n",
      "‚úÖ Spark session configured with:\n",
      "   - Driver Memory: 12GB\n",
      "   - Executor Memory: 8GB\n",
      "   - Max Result Size: 4GB\n",
      "   - Parallelism: 16 cores\n",
      "   - Shuffle Partitions: 200\n"
     ]
    }
   ],
   "source": [
    "#@title Start Spark session\n",
    "\n",
    "print(\"=== PRE-FLIGHT CHECK ===\")\n",
    "\n",
    "# Verify Java is available\n",
    "try:\n",
    "    java_version = subprocess.check_output(['java', '-version'], stderr=subprocess.STDOUT)\n",
    "    print(\"Java: ‚úÖ Available\")\n",
    "except Exception as e:\n",
    "    print(f\"Java: ‚ùå Not available - {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# üî• STOP any existing Spark sessions first\n",
    "try:\n",
    "    SparkContext.getOrCreate().stop()\n",
    "    print(\"üßπ Cleaned up existing Spark session\")\n",
    "except:\n",
    "    print(\"üÜï No existing session to clean\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create fresh Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Yelp_Sentiment_Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.default.parallelism\", \"16\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"512m\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"‚úÖ Spark session configured with:\")\n",
    "print(f\"   - Driver Memory: 12GB\")\n",
    "print(f\"   - Executor Memory: 8GB\")\n",
    "print(f\"   - Max Result Size: 4GB\")\n",
    "print(f\"   - Parallelism: 16 cores\")\n",
    "print(f\"   - Shuffle Partitions: 200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5eb74",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e034c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Creating train/validation/test splits...\n",
      "\n",
      "üìã Schema of Yelp Reviews:\n",
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- text_length: integer (nullable = true)\n",
      " |-- word_count: integer (nullable = true)\n",
      " |-- text_clean: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tokens_filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "\n",
      "üìã Sample:\n",
      "+--------------------------------------------------------------------------------+---------+-----------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|                                                                            text|sentiment|text_length|word_count|                                                                      text_clean|                                                                          tokens|                                                                 tokens_filtered|\n",
      "+--------------------------------------------------------------------------------+---------+-----------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|You think Value City, you think cheap value, right? Wrong! \\n\\nThink Rothman ...| negative|        974|       161|you think value city you think cheap value right wrong \\n\\nthink rothman pric...|[you, think, value, city, you, think, cheap, value, right, wrong, , , think, ...|[think, value, city, think, cheap, value, right, wrong, , , think, rothman, p...|\n",
      "|Walked by this place and decided to check it out. Great beer and burger place...| positive|        423|        73|walked by this place and decided to check it out great beer and burger place ...|[walked, by, this, place, and, decided, to, check, it, out, great, beer, and,...|[walked, place, decided, check, great, beer, burger, place, made, even, bette...|\n",
      "|Great store if you like 50's-Midcentury modern! The prices are a little high ...| positive|        163|        31|great store if you like 50smidcentury modern the prices are a little high com...|[great, store, if, you, like, 50smidcentury, modern, the, prices, are, a, lit...|[great, store, like, 50smidcentury, modern, prices, little, high, compared, f...|\n",
      "|The interior design is impeccable, the staff is friendly and the food is spot...| positive|        314|        57|the interior design is impeccable the staff is friendly and the food is spot ...|[the, interior, design, is, impeccable, the, staff, is, friendly, and, the, f...|[interior, design, impeccable, staff, friendly, food, spot, , , want, try, so...|\n",
      "|Love the food- wait staff is attentive to allergies and very accommodating. T...|  neutral|        192|        29|love the food wait staff is attentive to allergies and very accommodating the...|[love, the, food, wait, staff, is, attentive, to, allergies, and, very, accom...|[love, food, wait, staff, attentive, allergies, accommodating, drink, pours, ...|\n",
      "+--------------------------------------------------------------------------------+---------+-----------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Load dataset\n",
    "\n",
    "# Parquet path\n",
    "parquet_path = \"../data/clean/yelp_reviews_tokenized.parquet\"\n",
    "\n",
    "yelp_df = spark.read.parquet(parquet_path)\n",
    "\n",
    "print(\"\\nüìä Creating train/validation/test splits...\")\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "train_df, temp_df = yelp_df.randomSplit([0.7, 0.3], seed=42)\n",
    "val_df, test_df = yelp_df.randomSplit([0.5, 0.5], seed=42)\n",
    "\n",
    "# Show schema to understand structure\n",
    "print(\"\\nüìã Schema of Yelp Reviews:\")\n",
    "yelp_df.printSchema()\n",
    "\n",
    "# Samplo\n",
    "print(\"\\nüìã Sample:\")\n",
    "yelp_df.show(5, truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975695ac",
   "metadata": {},
   "source": [
    "## Logistic Regression with MLlib (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975695ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéØ BASELINE MODEL: Logistic Regression with TF-IDF\n",
      "================================================================================\n",
      "\n",
      "‚è≥ Training baseline model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Making predictions on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìà BASELINE RESULTS\n",
      "================================================================================\n",
      "Validation Accuracy: 0.8676\n",
      "Validation F1-Score: 0.8512\n",
      "Test Accuracy:       0.8628\n",
      "Test F1-Score:       0.8459\n",
      "================================================================================\n",
      "\n",
      "üîç Sample predictions (validation):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+---------+----------+\n",
      "|                                                                            text|sentiment|prediction|\n",
      "+--------------------------------------------------------------------------------+---------+----------+\n",
      "|!!!BEWARE, MAJOR SCAMMER, RIP OFF!!!\\nI called this company because of the go...| negative|       1.0|\n",
      "|\"A\" for effort and service. Same for price, very reasonable. Wine list expans...|  neutral|       1.0|\n",
      "|\"C-\"I know I know... it's a buffet but dear god! That was not sushi, not sure...|  neutral|       0.0|\n",
      "|\"Come on Man\"I only wanted a decent Saturday morning breakfast and received a...| negative|       1.0|\n",
      "|                     \"Delicious\" -Erock, Dan, Zeb\\n\\nChicken fried rice was tops| positive|       0.0|\n",
      "+--------------------------------------------------------------------------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üíæ Baseline model saved to: ../models/baseline_lr_tfidf\n"
     ]
    }
   ],
   "source": [
    "#@title Logistic Regression with TF-IDF (MLlib)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ BASELINE MODEL: Logistic Regression with TF-IDF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Convert sentiment labels to numerical indices\n",
    "# 0 -> Negative\n",
    "# 1 -> Neutral\n",
    "# 2 -> Positive\n",
    "label_indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n",
    "\n",
    "# Step 2: TF-IDF feature extraction\n",
    "# HashingTF: converts tokens to term frequency vectors\n",
    "hashingTF = HashingTF(inputCol=\"tokens_filtered\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "\n",
    "# IDF: applies inverse document frequency weighting\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Step 3: Logistic Regression classifier\n",
    "lr = LogisticRegression(\n",
    "    maxIter=20,\n",
    "    regParam=0.01,  # L2 regularization\n",
    "    elasticNetParam=0.0  # Pure L2 (ridge)\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "baseline_pipeline = Pipeline(stages=[label_indexer, hashingTF, idf, lr])\n",
    "\n",
    "# Train model\n",
    "print(\"\\n‚è≥ Training baseline model...\")\n",
    "baseline_model = baseline_pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nüìä Making predictions on validation set...\")\n",
    "val_predictions = baseline_model.transform(val_df)\n",
    "test_predictions = baseline_model.transform(test_df)\n",
    "\n",
    "# Evaluate\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "val_accuracy = evaluator_accuracy.evaluate(val_predictions)\n",
    "val_f1 = evaluator_f1.evaluate(val_predictions)\n",
    "\n",
    "test_accuracy = evaluator_accuracy.evaluate(test_predictions)\n",
    "test_f1 = evaluator_f1.evaluate(test_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà BASELINE RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1-Score: {val_f1:.4f}\")\n",
    "print(f\"Test Accuracy:       {test_accuracy:.4f}\")\n",
    "print(f\"Test F1-Score:       {test_f1:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show confusion matrix (validation)\n",
    "print(\"\\nüîç Sample predictions (validation):\")\n",
    "val_predictions.select('text', 'sentiment', 'prediction').show(5, truncate=80)\n",
    "\n",
    "# Save baseline model\n",
    "baseline_model_path = \"../models/baseline_lr_tfidf\"\n",
    "baseline_model.write().overwrite().save(baseline_model_path)\n",
    "print(f\"\\nüíæ Baseline model saved to: {baseline_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d0d377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä PREPARING DATA FOR TABLEAU\n",
      "================================================================================\n",
      "\n",
      "üìã Sample data for Tableau:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+--------------+----------+-----------+----------+-------------------+----------+\n",
      "|                                                                            text|true_sentiment|prediction|text_length|word_count|predicted_sentiment|is_correct|\n",
      "+--------------------------------------------------------------------------------+--------------+----------+-----------+----------+-------------------+----------+\n",
      "|! \\nBreakfast buffet offers omelettes and eggs made to order and is only 20 d...|      positive|       0.0|        213|        39|           negative|         0|\n",
      "|!!! Celiac Friendly !!!\\n\\nWhile they don't have a gluten-free menu, the staf...|      positive|       0.0|        470|        87|           negative|         0|\n",
      "|!!!!!!BE AWARE!!!!! I went to this place paid their fee put the application a...|      negative|       1.0|       1613|       320|            neutral|         0|\n",
      "|!!!The customer service is awful!!! The front desk was unable to find my rese...|      negative|       1.0|       1018|       188|            neutral|         0|\n",
      "|!00% Satisfied with this place. My Father and I go here often and we love it....|      positive|       0.0|        384|        70|           negative|         0|\n",
      "+--------------------------------------------------------------------------------+--------------+----------+-----------+----------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üìä Creating confusion matrix data...\n",
      "\n",
      "üî¢ Confusion Matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+------+\n",
      "|true_sentiment|predicted_sentiment| count|\n",
      "+--------------+-------------------+------+\n",
      "|      negative|           negative| 20066|\n",
      "|      negative|            neutral|134599|\n",
      "|      negative|           positive|  6563|\n",
      "|       neutral|           negative| 35548|\n",
      "|       neutral|            neutral| 17450|\n",
      "|       neutral|           positive| 16173|\n",
      "|      positive|           negative|451079|\n",
      "|      positive|            neutral|  8794|\n",
      "|      positive|           positive|  7314|\n",
      "+--------------+-------------------+------+\n",
      "\n",
      "\n",
      "üìà Creating per-class metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Per-class metrics:\n",
      "+--------+---------------+---------------+---------+------+---------+--------------+--------------+\n",
      "|f1_score|false_negatives|false_positives|precision|recall|sentiment|true_negatives|true_positives|\n",
      "+--------+---------------+---------------+---------+------+---------+--------------+--------------+\n",
      "|  0.9264|          16108|          55614|   0.8902|0.9655| negative|        174785|        451079|\n",
      "|  0.8358|          26629|          26244|   0.8368|0.8348|  neutral|        510114|        134599|\n",
      "|   0.326|          52998|          13877|   0.5382|0.2338| positive|        614538|         16173|\n",
      "+--------+---------------+---------------+---------+------+---------+--------------+--------------+\n",
      "\n",
      "\n",
      "üìè Creating text length analysis...\n",
      "\n",
      "üìä Text length by sentiment and correctness:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------------------+------------------+------+\n",
      "|true_sentiment|is_correct|   avg_text_length|    avg_word_count| count|\n",
      "+--------------+----------+------------------+------------------+------+\n",
      "|      positive|         1|1084.9219305441618|202.45187312004376|  7314|\n",
      "|      positive|         0|492.51661219510606| 90.96509905995786|459873|\n",
      "|       neutral|         1|  663.118452722063|125.10618911174785| 17450|\n",
      "|      negative|         0| 756.4438092404472|143.14610872614443|141162|\n",
      "|       neutral|         0| 671.3831325767096| 125.3961640339514| 51721|\n",
      "|      negative|         1|434.26975979268417| 81.64143327020831| 20066|\n",
      "+--------------+----------+------------------+------------------+------+\n",
      "\n",
      "\n",
      "üíæ Exporting to CSV for Tableau using Spark...\n",
      "\n",
      "‚è≥ Saving predictions sample...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Saving confusion matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Saving per-class metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Saving text length analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Saving model summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------+---------------------+--------------------+-----------------+\n",
      "|accuracy|correct_predictions|f1_score|incorrect_predictions|          model_name|total_predictions|\n",
      "+--------+-------------------+--------+---------------------+--------------------+-----------------+\n",
      "|  0.8628|              44830|  0.8459|               652756|Baseline (LR + TF...|           697586|\n",
      "+--------+-------------------+--------+---------------------+--------------------+-----------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ALL DATA EXPORTED FOR TABLEAU!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Files saved to: ../data/tableau/\n",
      "   Each folder contains CSV files (look for part-*.csv inside each folder)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#@title üíæ Export predictions for Tableau (FIXED - Direct Spark Export)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä PREPARING DATA FOR TABLEAU\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Get predictions with all relevant info\n",
    "tableau_predictions = test_predictions.select(\n",
    "    F.col('text'),\n",
    "    F.col('sentiment').alias('true_sentiment'),\n",
    "    F.col('prediction'),\n",
    "    F.col('text_length'),\n",
    "    F.col('word_count')\n",
    ").withColumn('predicted_sentiment',\n",
    "    F.when(F.col('prediction') == 0.0, 'negative')\n",
    "    .when(F.col('prediction') == 1.0, 'neutral')\n",
    "    .when(F.col('prediction') == 2.0, 'positive')\n",
    "    .otherwise('unknown')\n",
    ").withColumn('is_correct',\n",
    "    F.when(F.col('true_sentiment') == F.col('predicted_sentiment'), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "print(\"\\nüìã Sample data for Tableau:\")\n",
    "tableau_predictions.show(5, truncate=80)\n",
    "\n",
    "# 2. Create confusion matrix data\n",
    "print(\"\\nüìä Creating confusion matrix data...\")\n",
    "confusion_matrix = test_predictions.groupBy('sentiment', 'prediction').count()\n",
    "\n",
    "confusion_matrix_labeled = confusion_matrix.withColumn('predicted_sentiment',\n",
    "    F.when(F.col('prediction') == 0.0, 'negative')\n",
    "    .when(F.col('prediction') == 1.0, 'neutral')\n",
    "    .when(F.col('prediction') == 2.0, 'positive')\n",
    "    .otherwise('unknown')\n",
    ").select(\n",
    "    F.col('sentiment').alias('true_sentiment'),\n",
    "    F.col('predicted_sentiment'),\n",
    "    F.col('count')\n",
    ")\n",
    "\n",
    "print(\"\\nüî¢ Confusion Matrix:\")\n",
    "confusion_matrix_labeled.orderBy('true_sentiment', 'predicted_sentiment').show()\n",
    "\n",
    "# 3. Calculate metrics per class\n",
    "print(\"\\nüìà Creating per-class metrics...\")\n",
    "\n",
    "predictions_with_labels = test_predictions.select('label', 'prediction')\n",
    "\n",
    "# Calculate metrics for each class\n",
    "metrics_list = []\n",
    "for class_idx, class_name in enumerate(['negative', 'neutral', 'positive']):\n",
    "    tp = predictions_with_labels.filter(\n",
    "        (F.col('label') == class_idx) & (F.col('prediction') == class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    fp = predictions_with_labels.filter(\n",
    "        (F.col('label') != class_idx) & (F.col('prediction') == class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    fn = predictions_with_labels.filter(\n",
    "        (F.col('label') == class_idx) & (F.col('prediction') != class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    tn = predictions_with_labels.filter(\n",
    "        (F.col('label') != class_idx) & (F.col('prediction') != class_idx)\n",
    "    ).count()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    metrics_list.append({\n",
    "        'sentiment': class_name,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn,\n",
    "        'true_negatives': tn,\n",
    "        'precision': round(precision, 4),\n",
    "        'recall': round(recall, 4),\n",
    "        'f1_score': round(f1, 4)\n",
    "    })\n",
    "\n",
    "metrics_df = spark.createDataFrame(metrics_list)\n",
    "print(\"\\nüìä Per-class metrics:\")\n",
    "metrics_df.show()\n",
    "\n",
    "# 4. Text length analysis\n",
    "print(\"\\nüìè Creating text length analysis...\")\n",
    "length_analysis = tableau_predictions.groupBy('true_sentiment', 'is_correct').agg(\n",
    "    F.avg('text_length').alias('avg_text_length'),\n",
    "    F.avg('word_count').alias('avg_word_count'),\n",
    "    F.count('*').alias('count')\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Text length by sentiment and correctness:\")\n",
    "length_analysis.show()\n",
    "\n",
    "# 5. Export everything using Spark (NO PANDAS!)\n",
    "print(\"\\nüíæ Exporting to CSV for Tableau using Spark...\")\n",
    "\n",
    "output_dir = \"../data/tableau\"\n",
    "\n",
    "# SAVE DIRECTLY WITH SPARK - No toPandas()!\n",
    "print(\"\\n‚è≥ Saving predictions sample...\")\n",
    "tableau_predictions.limit(10000).coalesce(1).write.mode('overwrite').option('header', 'true').csv(f\"{output_dir}/predictions_sample\")\n",
    "\n",
    "print(\"\\n‚è≥ Saving confusion matrix...\")\n",
    "confusion_matrix_labeled.coalesce(1).write.mode('overwrite').option('header', 'true').csv(f\"{output_dir}/confusion_matrix\")\n",
    "\n",
    "print(\"\\n‚è≥ Saving per-class metrics...\")\n",
    "metrics_df.coalesce(1).write.mode('overwrite').option('header', 'true').csv(f\"{output_dir}/metrics_per_class\")\n",
    "\n",
    "print(\"\\n‚è≥ Saving text length analysis...\")\n",
    "length_analysis.coalesce(1).write.mode('overwrite').option('header', 'true').csv(f\"{output_dir}/text_length_analysis\")\n",
    "\n",
    "# 6. Create and save summary\n",
    "print(\"\\n‚è≥ Saving model summary...\")\n",
    "overall_summary = spark.createDataFrame([{\n",
    "    'model_name': 'Baseline (LR + TF-IDF)',\n",
    "    'accuracy': round(test_accuracy, 4),\n",
    "    'f1_score': round(test_f1, 4),\n",
    "    'total_predictions': test_predictions.count(),\n",
    "    'correct_predictions': tableau_predictions.filter(F.col('is_correct') == 1).count(),\n",
    "    'incorrect_predictions': tableau_predictions.filter(F.col('is_correct') == 0).count()\n",
    "}])\n",
    "\n",
    "overall_summary.show()\n",
    "overall_summary.coalesce(1).write.mode('overwrite').option('header', 'true').csv(f\"{output_dir}/model_summary\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ ALL DATA EXPORTED FOR TABLEAU!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìÅ Files saved to: {output_dir}/\")\n",
    "print(\"   Each folder contains CSV files (look for part-*.csv inside each folder)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656c0328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ predictions_sample.csv created\n",
      "‚úÖ confusion_matrix.csv created\n",
      "‚úÖ metrics_per_class.csv created\n",
      "‚úÖ text_length_analysis.csv created\n",
      "‚úÖ model_summary.csv created\n",
      "\n",
      "üéâ Clean CSVs ready for Tableau!\n"
     ]
    }
   ],
   "source": [
    "#@title Consolidate CSVs\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Move CSV files out of Spark folders\n",
    "output_dir = \"../data/tableau\"\n",
    "folders = ['predictions_sample', 'confusion_matrix', 'metrics_per_class', \n",
    "           'text_length_analysis', 'model_summary']\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = f\"{output_dir}/{folder}\"\n",
    "    csv_files = glob.glob(f\"{folder_path}/part-*.csv\")\n",
    "    \n",
    "    if csv_files:\n",
    "        csv_file = csv_files[0]\n",
    "        new_path = f\"{output_dir}/{folder}.csv\"\n",
    "        shutil.copy(csv_file, new_path)\n",
    "        print(f\"‚úÖ {folder}.csv created\")\n",
    "\n",
    "print(\"\\nüéâ Clean CSVs ready for Tableau!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
